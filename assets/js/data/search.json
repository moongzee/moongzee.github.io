[ { "title": "consumer-lag-monitoring", "url": "/posts/comsumer-lag-monitor/", "categories": "Stream Data Processing, kafka", "tags": "kafka, kafka consumer, mirrormaker, consumer lag, stream Data processing", "date": "2022-09-14 00:00:00 +0900", "snippet": "MirrorMaker consumer lag 모니터링목차 Consumer lag 이란? MirrorMaker Consumer lag 모니터링 프로그램 설명 Lag_monitor.py 설명 [번외] AWS cloudwatch 로 consumer lag 모니터링1. Consumer lag 이란?Kafka 의 producer가 보낸 메세지의 offset과 consumer가 받은 메세지의 offset 차이로, consumer의 상태 모니터링에 사용하는 지표 중 하나이다.2. MirrorMaker Consumer lag 모니터링 프로그램 설명MirrorMaker 구동시 제대로 작동하는지 모니터링하기 위해 consumer lag을 출력하는 쉘스크립트를 작성했었다.하지만, 연동하는 토픽이 많을수록 스크립트 실행 창을 여러개 띄워야해서 한곳에 모아 모니터링 하는 방법을 고민했었다.Consumer lag 모니터링의 주 목적은 다음과 같다. 연동하는 토픽 별 MirrorMaker Consumer lag 모니터링을 한 곳에 할 수 있다. Kibana 대시보드를 이용해 Consumer lag의 상태를 차트로 볼 수 있다.모니터링 프로그램 구성미러링하는 인스턴스의 consumer lag 정보를 Lag_monitor.py (모니터링을 위해 별도로 작성한 프로그램)을 통해 Elasticsearch로 보내고, Kibana 대시보드를 이용해 모니터링 한다. 3. Lag_monitor.py 설명Lag_monitor.py의 메인함수 프로세스는 3단계이다. Elasticsearch 연결 Elasticsearch Index 생성 파이프라인 함수 실행 여기서, 파이프라인 함수는 연동중인 토픽 별로 thread 실행을 한다.Lag_monitor.py의 Pipeline 함수 프로세스는 4단계이다. Consumer Lag 출력하는 command line 명령어 생성 함수를 실행 mirrormaker instance에 SSH 원격접속 에서 생성한 Consumer Lag을 출력하는 command line 명령어 실행 Consumer Lag 출력결과를 elasticsearch로 전송Lag_monitor.py 소스코드 설명 모듈 import Lag_monitor.py를 실행하기 위한 모듈을 불러온다.import timefrom datetime import datetimeimport jsonimport threadingimport paramikofrom elasticsearch import Elasticsearch1. Elasticsearch 연결Elasticsearch 모듈을 이용해 oasis-elasticsearch 서버와 연결을 한다.## connect elasticsearches = Elasticsearch(['http://es-node1-ip:9200',\t\t\t\t\t'http://es-node2-ip:9200',\t\t\t\t\t'http://es-node3-ip:9200'], \t\t\t\tbasic_auth=('ID','PW'))2. Elasticsearch Index 생성Consumer lag 정보를 저장할 index를 생성한다. ## create indexif es.indices.exists(index='consumer_lag') : passelse : with open('mapping.json', 'r') as f : mapping = json.load(f) es.indices.create (index='consumer_lag', body=mapping)index명은 consumer_lag으로 지정하였고, 만약 ‘consumer_lag’ index가 존재하면 index 생성과정을 넘긴다. ‘consumer_lag’ index의 schema 정보를 mapping.json 파일에 작성하였고, index 생성시 mapping.json 파일을 읽어 index의 schema 정보를 지정한다. mapping.json{ \"mappings\":{ \"properties\":{ \"@timestamp\":{\"type\" : \"date\"},\t\t\t\t\t\t\"topic\":{\"type\" : \"text\"},\t\t\t\t\t\t\"p0\":{\"type\" : \"integer\"},\t\t\t\t\t\t\"p1\":{\"type\" : \"integer\"},\t\t\t\t\t\t\"p2\":{\"type\" : \"integer\"},\t\t\t\t\t\t\"p3\":{\"type\" : \"integer\"},\t\t\t\t\t\t\"p4\":{\"type\" : \"integer\"},\t\t\t\t\t\t\"p5\":{\"type\" : \"integer\"},\t\t\t\t\t\t\"p6\":{\"type\" : \"integer\"},\t\t\t\t\t\t\"p7\":{\"type\" : \"integer\"},\t\t\t\t\t\t\"p8\":{\"type\" : \"integer\"},\t\t\t\t\t\t\"p9\":{\"type\" : \"integer\"},\t\t\t\t\t\t\"p10\":{\"type\" : \"integer\"},\t\t\t\t\t\t\"p11\":{\"type\" : \"integer\"},\t\t\t\t\t\t\"p12\":{\"type\" : \"integer\"},\t\t\t\t\t\t\"p13\":{\"type\" : \"integer\"},\t\t\t\t\t\t\"p14\":{\"type\" : \"integer\"},\t\t\t\t\t\t\"p15\":{\"type\" : \"integer\"},\t\t\t\t\t\t\"p16\":{\"type\" : \"integer\"},\t\t\t\t\t\t\"p17\":{\"type\" : \"integer\"} } }}3. 파이프라인 함수 실행파이프 라인 함수def lag_pipeline(ssh_key,es_conn,hostname,topic_name,monitor_cli,run_event): # SSH client 연결\t\tclient = paramiko.SSHClient() client.set_missing_host_key_policy(paramiko.AutoAddPolicy()) client.connect( hostname=hostname, username='ec2-user', pkey=ssh_key )\t # SSH 연결 후 consumer lag 지표 출력 shell script 명령어 실행에 따른 결과를 가져옴 \t\tstdin, stdout, stderr = client.exec_command(monitor_cli) \t\twhile True: line = stdout.readline() if not line: break\t\t\t\t# consumer lag 지표를 받아, 전처리 후 elasticsearch로 보냄 info = [datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%S.%f')[:-3]+'Z',topic_name] lag = line.split('\\n')[0].split(' ') dict1 = dict(zip(['@timestamp','topic'], info)) dict2 = {'p'+str(i) : lag[i] for i in range(len(lag))} document = dict(dict1, **dict2) es_conn.index(index='consumer_lag', body= document)Input parameter 설명 ssh_key mirrormaker instance ssh 접속에 필요한 key (ec2 pem file을 RSA key로 변환한 값) es_conn consumer lag의 값을 elasticsearch로 보내기 위해 elasticsearch와 연결한 client hostname mirrormaker instance ip 주소 topic_name consumer lag 지표를 수집하는 대상 토픽 명 monitor_cli consumer lag 지표를 출력하는 shell script 명령어consumer lag 지표 출력하는 shell script 명령어 생성 함수def lag_export_cli(source_bootstrap_server, mm_consumer_properties_file_nm, topic): cli_1 = \"while sleep 1; do echo -e $(/home/ec2-user/kafka_2.12-2.6.2/bin/kafka-consumer-groups.sh --bootstrap-server \" cli_2 = \" --group oasis-group --describe --command-config /home/ec2-user/kafka_2.12-2.6.2/config/\" cli_3 = \" --describe 2&gt; /dev/null | grep \" cli_4 = \" | sed 's/\\s\\+/\\\\t/g' | cut -f 6 | xargs); done\" cli = cli_1+str(source_bootstrap_server)+cli_2+str(mm_consumer_properties_file_nm)+cli_3+str(topic)+cli_4 return cliInput parameter 설명 source_bootstrap_server 토픽 연동하는 source kafka의 bootstrap server 주소 값 mm_consumer_properties_file_nm mirrormaker에서 사용하는 consumer properties 파일명 topic 미러링 대상 토픽명메인함수 내 파이프라인 함수 실행# 1. ec2 ssh 접속을 위한 key 생성key_path = 'ec2 pemfile path'ssh_key = paramiko.RSAKey.from_private_key_file(key_path)# 2. lag 추출 cli 명령어 생성t1_cli = lag_export_cli(source_bootstrap_server=\"source kafka bootstrap server\",\t\t\t\t\t\tmm_consumer_properties_file_nm=\"mirrormaker consumer properties file name\",\t\t\t\t\t\ttopic=\"topic name\"# 3. pipeline 함수 thread 실행t1 = threading.Tread(target=lag_pipeline, \t\t\t\t\t args=(ssh_key, es, 'ec2 mirrormaker ip', 'topic name', t1_cli)t1.start()미러링 대상 토픽별로 source kafka bootstrap, topic 명, mirrormaker 인스턴스 ip주소, mirrormaker consumer properties 파일명을 수정하여 pipeline 함수 thread를 생성한다.1. ec2 ssh 접속을 위한 key 생성ssh_key 변수에 ec2 접속을 위한 pem file을 이용해 RSA key로 변환한 값을 할당한다.** pem file 경로 : /home/ec2-user/launcher/pemfile/ec2_keypair_dev.pem2. lag_export_cli 함수 실행인자값으로 source kafka bootstrap_server 주소, mirror maker consumer properties file 명, 토픽 명을 입력하여 consumer lag 추출하는 command line 명령어를 생성후 t1_cli 변수에 할당한다.3. 파이프라인 함수를 thread로 실행threading 모듈의 thread 함수를 사용하며,인자값으로는 target 과 args 가 있다. target thread 실행할 함수명 즉, lag_pipeline을 입력한다 args lag_pipeline 함수의 인자값 (ssh_key , es_conn , hostname , topic_name , monitor_cli )을 차례대로 입력한다.[번외] AWS cloudwatch 로 consumer lag 모니터링프로젝트 수행시 위와 같은 방법으로 consumer lag 모니터링을 했으나, role off 후 cloudwatch에 custom metric을 보낼 수 있다는 것을 알게되었다.그래서 Toy project로 MirrorMaker의 consumer lag을 AWS cloudwatch에 custom metric으로 보내는 쉘스크립트를 작성하여 실습해보았다.ArchitectureAWS CLI Cloudwatch 서비스의 put-metric-data 명령어를 활용해 mirrormaker의 consumer lag 지표를 AWS CLoudwatch 에 custom metric으로 보내는 구조이다.consumer-lag_to_cloudwatch.shwhile true; dolag=$(/home/ec2-user/kafka_2.12-2.6.2/bin/kafka-consumer-groups.sh \\\t\t--bootstrap-server {source kafka bootstrap server} \\\t\t--group {mirrormaker consumer group} \\\t\t--describe \\\t\t--command-config /home/ec2-user/kafka_2.12-2.6.2/config/{mirrormaker consumer properties} \\\t\t--describe 2&gt; /dev/null | grep test | sed 's/\\s\\+/\\t/g' | cut -f 6 | xargs)aws cloudwatch put-metric-data \\--namespace {custom metric namespace}--metric-name {custom metric name}--value $lagecho -e -n \"$(date)\\t\"echo -e -n \"topic: {topicname}\\t\"echo -e -n \"consumer-lag\\t\"echo -e $lagsleep 1done파티션별 consumer lag 값을 가져오는 것은 따로 --dimesion이라는 속성값으로 구분을 해야할거같음?? (관련해서는 더 찾아봐야함)consumer-lag_to_cloudwatch.sh 실행 화면앞의 쉘스크립트를 실행하면 해당 토픽의 consumer lag의 값이 콘솔창에 출력이 된다.Cloudwatch에서 custom metric 대시보드 화면Custom mertric으로 받은 MirrorMaker consumer lag 의 값을 그림과 같이 cloudwatch 대시보드에서 확인 가능하다." }, { "title": "kafka-consumer", "url": "/posts/kafka-consumer/", "categories": "Stream Data Processing, kafka", "tags": "kafka, kafka-consumer, stream Data processing", "date": "2022-09-13 00:00:00 +0900", "snippet": "Kafka consumerkafka consumer 란데이터 read(poll) 주체commit을 통해 consumer offset을 카프카에 기록consumer가 자동이나 수동으로 읽은 데이터의 위치를 commit하여 다시 읽음을 방지한다__consumer_offsets라는 Internal Topic에서 consumer offset을 저장하여 관리한다consumer 작동 방식1. single consumerTopic의 모든 partition 에서 모든 Record를 consume한다.2. multiple consumer 동일한 group.id로 구성된 모든 consumer들은 하나의 consumer group을 형성한다.partition 은 항상 consumer group에서 하나의 consumer에 의해서만 사용이 된다.consumer group의 consumer들은 작업량을 어느정도 균등하게 분할한다. 다른 consumer group의 consumer들은 분리되어 독립적으로 작동이 된다.3. consumer group 과 rebalancing consumer group의 consumer는 자신들이 읽는 토픽 파티션의 소유권을 공유한다.새로운 consumer를 그룹에 추가할때, 특정 consumer에 문제가 생겨 중단될때 consumer가 오랫동안 하트비트를 보내지 않으면 세션 타임아웃 일어난다.Rebalancing 하는 동안에는 consumer들은 메세지를 읽을 수 없으므로 해당 그룹 전체가 잠시 사용 불가능하다. Rebalancing : 한 consumer로 부터 다른 consumer로 파티션 소유권을 이전하는 것commit 과 offset commit 파티션 내부의 현재 위치를 변경하는 것 offset 컨슈머 자신이 읽는 레코드의 현재 위치 리밸런싱의 문제가 발생하면, 각 consumer는 이전과 다른 파티션을 할당받게 될 수 있다. 이에 따라 메세지를 중복처리하거나 유실되는 경우가 있다. 특히, consumer 를 구성할 때, enable.auto.commit=true 로 두면 아래와 같은 경우 발생가능성이 있음.1. 중복처리 경우2. 유실되는 경우consumer 구성에서 중요한 configuration auto.offset.reset 커밋된 오프셋이 없는 파티션을 컨슈머가 읽기 시작할때, 또는 커밋된 오프셋이 있지만 유효하지 않을때, 컨슈머가 어떤 레코드를 읽을지 제어하는 매개변수 latest(default) (컨슈머가 실행 된 후 새로 추가된 레코드들) 을 읽음 earliest 해당 파티션의 맨 앞부터 모든 데이터를 읽음 enable.auto.commit 컨슈머의 오프셋 커밋을 자동으로 할 것인지에 대한 제어 true(default) ; auto.commit.interver.ms 로 자동으로 오프셋 커밋하는 시간 간격을 제어 할 수 있다. 속도가 가장 빠르고, commit 관련 코드를 작성할 필요가 없는 장점이 있다. false ; commitSync, commitAsync 사용 하여 offset commit을 제어함자동 커밋 상황자동 커밋 중 리밸런스가 일어났을 때 commitSync : 현재 오프셋 커밋 consumerRecord 처리순서를 보장한다. 가장느림 ( 커밋이 완료될 때 까지 block ) poll() method로 반환된 consumerRecord의 마지막 offset을 커밋한다.commitAsync commitSync 보다는 빠르다 중복이 발생할 수 있다 consumerRecord 처리 순서를 보장하지 못한다브로커의 commit 응답을 기다리는 대신, commit 요청을 전송하고 처리를 계속 할 수 있음 일싲거인 통신문제로 이전 offset 보다 이후 offset 이 먼저 commit 이 될 때offset을 다루는 방법1. Consumer Group의 offset 상태 확인consumer group을 지정하고 --describe옵션을 사용하면 현재 consumer group의 offset 정보를 볼 수 있다.명령어는 다음과 같다.kafka-consumer-groups \\--bootstrap-server &lt;host:port&gt; \\--group &lt;group.id&gt; \\--describe실행결과 예시TOPIC PARTITION CURRENT-OFFSET LOG-END-OFFSET LAG CONSUMER-ID HOST CLIENT-IDexample.topic 0 6392623366 6392623859 493 consumer-1-f6f6ffb0-1054-46b9-af13-0b254bc14da0 /10.64.69.95 consumer-1example.topic 1 6394637143 6394637383 240 consumer-10-6c57b320-7742-4418-8e15-b7d735da346e /10.64.69.95 consumer-2example.topic 2 6397170269 6397170495 226 consumer-19-dbed41a1-42bb-4ecb-bc8f-84e47c74dbe8 /10.64.69.95 consumer-3example.topic 3 6397170269 6397170495 226 consumer-19-dbed41a1-42bb-4ecb-bc8f-84e47c74dbe8 /10.64.69.95 consumer-4 TOPIC 토픽 이름 PARTITION consumer group 내의 각 consumer가 할당된 파티션 번호 CURRENT-OFFSET 현재 consumer group의 consumer가 각 파티션에서 마지막으로 offset을 commit한 값 LOG-END-OFFSET producer쪽에서 마지막으로 생성한 레코드의 offset LAG LOG-END-OFFSET에서 CURRENT-OFFSET를 뺀 값.--describe를 통해 조회를 했을때 LAG이 계속 일정 수준을 유지한다면 consumer가 producer 가 만들어내는 이벤트 레코드의 양을 잘 따라가고있다는 것을 확인할 수 있다. 하지만 LAG이 계속 증가한다면 consumer의 처리 속도가 느린 것이기 때문에 consumer의 갯수를 충분히 증가시키거나, consumer의 로직을 더 간략화 해서 빠른 속도로 데이터 처리를 할 수 있도록 변경해야 한다.2. Consumer Group의 offset resetkafka에서 데이터를 불러와서 처리하는 과정에서 오류가 발생하거나 문제가 발견된 경우,다시 원하는 offset부터 데이터를 재처리를 해야할 경우가 종종 있다. 이때 consumer group의 offset reset 기능을 활용하면 된다.** consumer group이 실행중인 상태에 offset reset을 진행하는 경우 reset은 실패한다.kafka-consumer-groups \\--bootstrap-server &lt;host:port&gt; \\--group &lt;group&gt; \\--topic &lt;topic&gt; \\--reset-offsets \\--to-earliest \\--execute-topic 대신 -all-topics를 지정하면 모든 토픽에 대해서 실행이 가능하다.-execute 옵션을 제거하고 실행하면 실제 반영되지 않고 어떻게 변할지 결과만 출력하는 dry run이 가능하다.offset 의 위치를 재설정 하기 위한 옵션 -shift-by &lt;Long: number-of-offsets&gt; 형식 (+/- 모두 가능)-to-offset &lt;Long: offset&gt;-to-current-by-duration &lt;String: duration&gt; : 형식 ‘PnDTnHnMnS’-to-datetime &lt;String: datetime&gt; : 형식 ‘YYYY-MM-DDTHH:mm:SS.sss’-to-latest-to-earliest** --to-datetime의 경우 kafka에서 데이터를 읽어서 다른곳에 저장하는 중에 데이터 유실 또는 중복 write 등이 발생한 경우에 날짜 단위로 데이터를 다시 불러와서 재처리하고 싶은 경우 매우 유용하다.예시 &gt; 특정 topic의 파티션 1번만 offset을 30으로 지정하고 싶을때./kafka-consumer-groups \\--bootstrap-server {bootstrap 정보} \\--group click --topic {topic명}:1 \\--reset-offsets --to-offset 30 --execute" } ]
